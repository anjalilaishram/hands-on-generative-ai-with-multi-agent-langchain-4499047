{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OKXJtqZxrXD"
      },
      "source": [
        "# Multi-agent decentralized speaker selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74Nm3v51xrXG"
      },
      "source": [
        "## Import LangChain related modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1XOGESnxrXG"
      },
      "outputs": [],
      "source": [
        "# Use termcolor to make it easy to colorize the outputs.\n",
        "!pip install termcolor > /dev/null\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install langchain_experimental\n",
        "!pip install tiktoken\n",
        "!pip install faiss-cpu==1.7.4\n",
        "from typing import Callable, List\n",
        "import tenacity\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import RegexParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import (\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        ")\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvbClQNSxrXH"
      },
      "source": [
        "## `DialogueAgent` and `DialogueSimulator` classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_jBDa-T3dmZ"
      },
      "outputs": [],
      "source": [
        "class DialogueAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        system_message: SystemMessage,\n",
        "        model: ChatOpenAI,\n",
        "    ) -> None:\n",
        "        self.name = name\n",
        "        self.system_message = system_message\n",
        "        self.model = model\n",
        "        self.prefix = f\"{self.name}: \"\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.message_history = [\"Here is the conversation so far.\"]\n",
        "\n",
        "    def send(self) -> str:\n",
        "        \"\"\"\n",
        "        Applies the chatmodel to the message history\n",
        "        and returns the message string\n",
        "        \"\"\"\n",
        "        message = self.model(\n",
        "            [\n",
        "                self.system_message,\n",
        "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
        "            ]\n",
        "        )\n",
        "        return message.content\n",
        "\n",
        "    def receive(self, name: str, message: str) -> None:\n",
        "        \"\"\"\n",
        "        Concatenates {message} spoken by {name} into message history\n",
        "        \"\"\"\n",
        "        self.message_history.append(f\"{name}: {message}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
